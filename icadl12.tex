\documentclass[runningheads,a4paper]{llncs}

\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx}

\usepackage{url}

\begin{document}

\mainmatter

\title{Automatic Perspective Correction of Manuscript Images}

\author{Ryan Baumann\inst{1} \and Christopher Blackwell\inst{2} \and W. Brent Seales\inst{1}}

\institute{University of Kentucky
\and
Furman University}

\maketitle

\section{Introduction}

Frequently, images of rare documents must be taken under strict time constraints, 
when a chance opportunity arises, and with equipment that is less than ideally suited 
for precise digitization. This can often result in uncalibrated images
whose contents are nonetheless qualitatively useful. Due to the logistics of document
imaging, perspective distortion is a common artifact which can manifest itself in
images taken under these constrained circumstances. We propose an automated approach for
correcting this perspective distortion, even for uncalibrated images of documents
with irregular page edges containing no regular text.

\section{Background}

Details about imaging here.

\section{Related Work}

Numerous work exists for performing document perspective correction by exploiting the presence of
common text features, such as linear text baselines in printed texts.
As a result, many of these techniques need to be tweaked depending upon morphological features of
the written language of the document in question.
However, for our documents,
many pages had no such features, consisting only of handwritten text and physical plant
specimens. As a result, our approach is fairly unique in that it uses only physical page boundaries to
perform the perspective correction. An advantage to this is that it can handle “blank” pages or pages
consisting only of images or haphazard writing. In addition, because the manuscript pages we are dealing with have
cockled, uneven edges, our boundary detection needs to be relatively robust to the “noise” of these uneven edges.

\section{Perspective Correction Algorithm}

The perspective correction algorithm functions by applying a few steps in sequence:

\begin{enumerate}
  \item Foreground/background segmentation.
  \item Canny edge detection followed by dilation to turn the mask image into a line image.
  \item Hough line detection to detect lines.
  \item Line classification to classify the detected lines as “top” or “bottom” page edge lines.
  \item Line averaging to find the “average” line for the top and bottom edge lines.
  \item Compute homography for transforming the slanted top and bottom page lines into straight lines.
  \item Application of the resulting perspective warp.
\end{enumerate}

For our images, most were made with a fairly consistent backdrop, so the foreground/background segmentation operates by performing a flood fill on the corners of a gaussian-smoothed version of the image. This exploits the assumption that the page will not fill the full image all the way around, as in such a case, our perspective correction would likely be unable to accurately detect all the page edges which it uses to compute homography.

This gives us a mask image as seen in figure (figure ref here). Since we want to use Hough line detection, we first need to transform the mask edges into lines, which we do using a Canny edge detector and dilation, the results of which can be seen in figure (figure ref here).

\section{Results}

\section{Conclusions and Future Work}

\section{Acknowledgments}

\bibliographystyle{splncs}
\bibliography{icadl12}

\end{document}
